{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GEPA Behavior Demo\n",
        "\n",
        "This notebook initializes the simulation and behavior model, runs a minimal rollout, and visualizes logs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os, sys\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "from gepa.utils.config import Config, ConfigLoader\n",
        "from gepa.utils.logging_utils import Logger\n",
        "from gepa.sim import BulletSimEnv\n",
        "from gepa.models import TorchBehaviorModel\n",
        "from gepa.gepa import GEPAOptimizer, MockLLM, Prompt\n",
        "import torch, numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = ConfigLoader.from_yaml('../configs/default.yaml')\n",
        "env = BulletSimEnv(urdf_path=cfg.simulation.robot_urdf, gui=False)\n",
        "obs = env.reset()\n",
        "cfg.model.input_dim = int(obs.shape[0])\n",
        "cfg.model.action_dim = int(env.num_joints)\n",
        "model = TorchBehaviorModel(architecture=cfg.model.architecture, input_dim=cfg.model.input_dim, action_dim=cfg.model.action_dim, prompt_conditioning=cfg.model.prompt_conditioning)\n",
        "logger = Logger('../runs/notebook_demo')\n",
        "prompt = cfg.gepa.base_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards = []\n",
        "observations = []\n",
        "actions = []\n",
        "for t in range(100):\n",
        "    observations.append(obs.copy())\n",
        "    obs_t = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
        "    action = model.select_action(obs_t, prompt=prompt).action.squeeze(0).numpy()\n",
        "    actions.append(action.copy())\n",
        "    res = env.step(action)\n",
        "    obs = res.observation\n",
        "    rewards.append(res.reward)\n",
        "logger.log_trajectory('demo_episode', observations, actions, rewards)\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gepa.utils.plotting import plot_trajectory\n",
        "plot_trajectory(rewards)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
